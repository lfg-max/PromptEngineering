{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary='A palm tree stands on a sandy beach with the ocean in the background.' objects=[Object(name='tree', confidence=1.0, attributes='palm tree'), Object(name='ground', confidence=1.0, attributes='sand')] scene='beach' colors=['#000000', '#FF0000', '#00FF00', '#0000FF', '#FFFF00'] time_of_day='Afternoon' setting='Outdoor' text_content='The image shows a palm tree standing on a sandy beach, with the ocean visible in the background. The sky is blue and cloudy, suggesting that it is afternoon. The overall atmosphere of the image is one of relaxation and tranquility, evoking feelings of warmth and sunshine.'\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional, Literal\n",
    "\n",
    "class Object(BaseModel):\n",
    "  name: str\n",
    "  confidence: float\n",
    "  attributes: str \n",
    "\n",
    "class ImageDescription(BaseModel):\n",
    "    summary: str\n",
    "    objects: List[Object]\n",
    "    scene: str\n",
    "    colors: List[str]\n",
    "    time_of_day: Literal['Morning', 'Afternoon', 'Evening', 'Night']\n",
    "    setting: Literal['Indoor', 'Outdoor', 'Unknown']\n",
    "    text_content: Optional[str] = None\n",
    "\n",
    "path = 'beach.jpg'\n",
    "\n",
    "response = chat(\n",
    "  model='llama3.2-vision',\n",
    "  format=ImageDescription.model_json_schema(),  # Pass in the schema for the response\n",
    "  messages=[\n",
    "    {\n",
    "      'role': 'user',\n",
    "      'content': 'Analyze this image and describe what you see, including any objects, the scene, colors and any text you can detect.',\n",
    "      'images': [path],\n",
    "    },\n",
    "  ],\n",
    "  options={'temperature': 0},  # Set temperature to 0 for more deterministic output\n",
    ")\n",
    "\n",
    "image_description = ImageDescription.model_validate_json(response.message.content)\n",
    "print(image_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
